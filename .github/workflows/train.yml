name: Continuous Training and Deployment

on:
  schedule:
    - cron: "0 0 * * *" # Run every day at midnight
  workflow_dispatch: # Run manually
  push:
    branches:
      - main

jobs:
  train_and_deploy:
    runs-on: ubuntu-latest

    steps:
      # Step 1: Checkout the repository
      - name: Checkout repository
        uses: actions/checkout@v3

      # Step 2: Set up Git user identity
      - name: Configure Git User
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"

      # Step 3: Set up Python environment
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.9

      # Step 4: Install dependencies
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install dvc[all]
          pip install -r requirements.txt

      # Step 5: Configure Google Drive credentials
      - name: Configure Google Drive credentials
        env:
          GDRIVE_SERVICE_ACCOUNT_BASE64: ${{ secrets.GDRIVE_SERVICE_ACCOUNT_BASE64 }}
        run: |
          echo "${{ secrets.GDRIVE_SERVICE_ACCOUNT_BASE64 }}" | base64 --decode > google_services.json

      # Step 6: Configure DVC Remote for Google Drive
      - name: Configure DVC Remote
        run: |
          dvc remote modify storage gdrive_use_service_account true
          dvc remote modify storage gdrive_service_account_json_file_path google_services.json

      # Step 7: Pull dataset from DVC remote storage
      - name: Pull dataset
        run: dvc pull

      # Step 8: Train model locally
      - name: Train model locally
        run: |
          python src/data_ingestion/youtube_comments/main.py
          python src/scripts/main.py
          python src/models/train_model.py
          dvc add data/train.csv
          git add data/train.csv.dvc
          git commit -m "Update dataset"
          dvc push

      # Step 9: Transfer trained model to server
      - name: Transfer trained model to server
        uses: appleboy/scp-action@v0.1.1
        with:
          source: src/models/emotion_classifier_pipe_lr.pkl
          target: ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_IP }}:/tmp/emotion_classifier_pipe_lr.pkl

      # Step 10: Copy model to container and clean up
      - name: Deploy and update model in container
        uses: appleboy/ssh-action@v0.1.9
        with:
          host: ${{ secrets.SERVER_IP }}
          username: ${{ secrets.SERVER_USER }}
          key: ${{ secrets.SERVER_SSH_KEY }}
          script: |
            set -e

            # Check if the model file exists in the container
            if docker exec flask_app_1 test -f /app/src/models/emotion_classifier_pipe_lr.pkl; then
              echo "Model file already exists. Backing up..."
              docker exec flask_app_1 mv /app/src/models/emotion_classifier_pipe_lr.pkl /app/src/models/emotion_classifier_pipe_lr_backup_$(date +%Y%m%d%H%M%S).pkl
            fi

            # Copy the new model file to the container
            docker cp /tmp/emotion_classifier_pipe_lr.pkl flask_app_1:/app/src/models/emotion_classifier_pipe_lr.pkl

            # Remove temporary model file from the server
            rm /tmp/emotion_classifier_pipe_lr.pkl

            # Rebuild and redeploy the application container
            cd docker/experiments/insight-sync-application 
            docker compose up -d --build
